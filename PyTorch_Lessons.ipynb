{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Lessons.ipynb",
      "provenance": [],
      "mount_file_id": "1UMUF58Bw77klJPCNAjiSEV3KkqH0fp9S",
      "authorship_tag": "ABX9TyN7QqZ1rJ0z9HKrzc7WLXpc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArindamMukerjee/PyTorch_Tutorial/blob/master/PyTorch_Lessons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBn64e9AKGCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYnaht9pKHyl",
        "colab_type": "code",
        "outputId": "89ee0f1f-a40c-4181-d381-c6c5116f81ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_1QcKRaQC5T",
        "colab_type": "text"
      },
      "source": [
        "## Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0N1uo4eKLf_",
        "colab_type": "code",
        "outputId": "d95bedfc-9303-4bfa-c434-d30eb8e8f8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# tensor operations\n",
        "x = torch.empty(2, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2247e-35, 0.0000e+00, 1.5975e-43],\n",
            "        [1.3873e-43, 1.4574e-43, 6.4460e-44]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4GCYdUEKjRU",
        "colab_type": "code",
        "outputId": "1b23558b-b5f3-451e-c944-0f5ee0705a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "torch.rand(2, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3969, 0.9359],\n",
              "        [0.0528, 0.7492]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAQBYEq0K0jd",
        "colab_type": "code",
        "outputId": "fedf6b4d-e78c-4689-b2bb-8f7b20508d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "torch.zeros(2, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_C7-aEUK32C",
        "colab_type": "code",
        "outputId": "b8312794-7862-4c4d-b59e-4f48334f9e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tensor with a specific datatype\n",
        "x = torch.ones(2, 2, dtype = torch.int)\n",
        "print(x.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD80KRsRLEO1",
        "colab_type": "code",
        "outputId": "1cb39c6d-8d8f-4778-aad9-0bbbe1fa79c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# from a numpy array\n",
        "torch.tensor(np.random.random([3, 3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2498, 0.6714, 0.5926],\n",
              "        [0.4261, 0.2380, 0.6748],\n",
              "        [0.6482, 0.7705, 0.4645]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd6IdQkcLZDc",
        "colab_type": "code",
        "outputId": "433a170e-94f3-41ce-8a04-2c84a1690039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# add and update a tensor\n",
        "x = torch.rand(2, 2) \n",
        "y = torch.rand(2, 2)\n",
        "y.add_(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7365, 1.0182],\n",
              "        [1.0378, 1.0005]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1FIrybMNzKW",
        "colab_type": "code",
        "outputId": "5af13d30-252e-4f9d-cb68-406a3f206f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# save a tensor to gpu (it can't be converted to numpy)\n",
        "device = torch.device('cuda')\n",
        "x = torch.ones(5)\n",
        "x.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO_ZO6ccQGJr",
        "colab_type": "text"
      },
      "source": [
        "## Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T3dcP-sQHoj",
        "colab_type": "code",
        "outputId": "c10404dc-d055-4e0d-a023-5859e1825c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.5050,  0.7355,  0.0447], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLSXtxfBQLQs",
        "colab_type": "code",
        "outputId": "667b1adb-25e4-4998-e2cc-2052d7a20ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# gradients with a scalar output\n",
        "y = x + 2\n",
        "z = y * y * 2\n",
        "z = z.mean()\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.9934, 3.6473, 2.7263])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI7Z9ESWQUBp",
        "colab_type": "code",
        "outputId": "49770958-1a3b-4ee4-8e8f-f8e83dd8dec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# gradients with vector output\n",
        "y = x + 2\n",
        "z = y * y * 2\n",
        "vec = torch.tensor([0.1, 1.0, .001], dtype = torch.float32)\n",
        "z.backward(vec)\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.5914, 14.5893,  2.7345])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX2ATmwAQly_",
        "colab_type": "code",
        "outputId": "bc6b6229-5d20-4ca3-e9ce-fa6885356e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prevent function from tracking gradients\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.3093, -0.8800,  1.1363])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBO4F_-GQ5X5",
        "colab_type": "code",
        "outputId": "41935447-e0fe-4167-eb10-a0ff5d00edb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# second option\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "y = x.detach()\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.1350, -0.7366,  1.0328])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6gFlTMqRE_2",
        "colab_type": "code",
        "outputId": "f780db53-6363-44ff-bf48-03e3c6d4da63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# third option\n",
        "with torch.no_grad():\n",
        "  y = x + 2\n",
        "  print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8650, 1.2634, 3.0328])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHHhmWsYRJQ0",
        "colab_type": "code",
        "outputId": "4224d0b9-6ce7-41ca-ec76-aa701febd96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# method to make sure that weights do not accumulate\n",
        "weights = torch.ones(4, requires_grad = True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights * 3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-Au0pJWade",
        "colab_type": "text"
      },
      "source": [
        "## Backprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z641R9sHSNEl",
        "colab_type": "code",
        "outputId": "2868e8d1-5b22-40ba-ea73-6853ed9e1eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad = True)\n",
        "\n",
        "# forward pass\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weight and continue forward and backward pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6IA2lBoZR7d",
        "colab_type": "text"
      },
      "source": [
        "## Gradient from scratch (2 methods)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4w49aXwZJas",
        "colab_type": "code",
        "outputId": "3c3ad49d-10a6-4ba4-9e60-9f0ba575bdeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# manual learning\n",
        "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype = np.float32)\n",
        "w = 0.0\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.dot(2 * x, y_pred - y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # prediction\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'epoch {epoch+1} : w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {forward(5) : .3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1 : w = 1.200, loss = 30.00000000\n",
            "epoch 2 : w = 1.680, loss = 4.79999924\n",
            "epoch 3 : w = 1.872, loss = 0.76800019\n",
            "epoch 4 : w = 1.949, loss = 0.12288000\n",
            "epoch 5 : w = 1.980, loss = 0.01966083\n",
            "epoch 6 : w = 1.992, loss = 0.00314574\n",
            "epoch 7 : w = 1.997, loss = 0.00050331\n",
            "epoch 8 : w = 1.999, loss = 0.00008053\n",
            "epoch 9 : w = 1.999, loss = 0.00001288\n",
            "epoch 10 : w = 2.000, loss = 0.00000206\n",
            "Prediction after training : f(5) =  9.999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIsGizWQaT2B",
        "colab_type": "code",
        "outputId": "f039a080-1eaf-401e-c437-51bdaafee272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# automated gradient\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, requires_grad = True, dtype = torch.float32)\n",
        "\n",
        "# model prediction \n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# learning\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "for epoch in range(n_iters):\n",
        "    # prediction\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    \n",
        "    # zero gradients\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch + 1} : w = {w : .3f}, loss = {l : .8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {forward(5) : .3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 : w =  0.300, loss =  30.00000000\n",
            "epoch 3 : w =  0.772, loss =  15.66018772\n",
            "epoch 5 : w =  1.113, loss =  8.17471695\n",
            "epoch 7 : w =  1.359, loss =  4.26725292\n",
            "epoch 9 : w =  1.537, loss =  2.22753215\n",
            "epoch 11 : w =  1.665, loss =  1.16278565\n",
            "epoch 13 : w =  1.758, loss =  0.60698116\n",
            "epoch 15 : w =  1.825, loss =  0.31684780\n",
            "epoch 17 : w =  1.874, loss =  0.16539653\n",
            "epoch 19 : w =  1.909, loss =  0.08633806\n",
            "Prediction after training : f(5) =  9.612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXNNZ94golwv",
        "colab_type": "text"
      },
      "source": [
        "## Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee2kmoy6onG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAOx1FjFo6U2",
        "colab_type": "code",
        "outputId": "61e5448d-7a20-4d93-80ed-51378c4e01cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32).reshape(4, 1)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32).reshape(4, 1)\n",
        "\n",
        "X_test = torch.tensor([5], dtype = torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# pytorch model\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item() : .3f}')\n",
        "\n",
        "# training \n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # prediction\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters()\n",
        "        print(f'epoch {epoch + 1} : w = {w[0][0].item() : .3f}, loss = {l : .8f}')\n",
        "\n",
        "print(f'Prediction after training {model(X_test).item() : .3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training : f(5) =  3.697\n",
            "epoch 1 : w =  0.791, loss =  10.45881748\n",
            "epoch 11 : w =  1.536, loss =  0.41821748\n",
            "epoch 21 : w =  1.664, loss =  0.14985111\n",
            "epoch 31 : w =  1.692, loss =  0.13481550\n",
            "epoch 41 : w =  1.704, loss =  0.12680523\n",
            "epoch 51 : w =  1.713, loss =  0.11942028\n",
            "epoch 61 : w =  1.722, loss =  0.11246924\n",
            "epoch 71 : w =  1.730, loss =  0.10592294\n",
            "epoch 81 : w =  1.738, loss =  0.09975767\n",
            "epoch 91 : w =  1.746, loss =  0.09395130\n",
            "Prediction after training  9.490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lraLSloAuvBu",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFA231ixuwZZ",
        "colab_type": "code",
        "outputId": "346df2a0-c13e-4eae-f7f2-7348a854db32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data prep\n",
        "X, y = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)\n",
        "\n",
        "X = torch.from_numpy(X.astype(np.float32))\n",
        "y = torch.from_numpy(y.astype(np.float32)).reshape(-1, 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# model definition\n",
        "model = nn.Linear(n_features, 1)\n",
        "\n",
        "# loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # forward pass and loss\n",
        "    y_pred = model(X)\n",
        "    loss = criterion(y_pred, y)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # weight update\n",
        "    optimizer.step()\n",
        "\n",
        "    # empty gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'epoch : {epoch + 1}, loss = {loss.item() : .4f}')\n",
        "\n",
        "# plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X, y, 'ro')\n",
        "plt.plot(X, predicted, 'b')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 10, loss =  4396.3535\n",
            "epoch : 20, loss =  3279.5200\n",
            "epoch : 30, loss =  2471.5444\n",
            "epoch : 40, loss =  1886.3839\n",
            "epoch : 50, loss =  1462.1691\n",
            "epoch : 60, loss =  1154.3488\n",
            "epoch : 70, loss =  930.7967\n",
            "epoch : 80, loss =  768.3163\n",
            "epoch : 90, loss =  650.1384\n",
            "epoch : 100, loss =  564.1260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqL_3eqPxZdT",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3npHDZlrxt0d",
        "colab_type": "code",
        "outputId": "55d8558d-0b60-4b0a-a6b3-7a59665d77c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data prep\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32)).reshape(-1, 1)\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32)).reshape(-1, 1)\n",
        "\n",
        "# model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_predicted = torch.sigmoid(self.linear(x))\n",
        "        return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # forward pass and loss\n",
        "    y_predicted = model(X_train)\n",
        "    loss = criterion(y_predicted, y_train)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # weight updates\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # print values\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'epoch : {epoch + 1}, loss = {loss.item() : .4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy = {acc : .4f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 10, loss =  0.6836\n",
            "epoch : 20, loss =  0.5266\n",
            "epoch : 30, loss =  0.4362\n",
            "epoch : 40, loss =  0.3788\n",
            "epoch : 50, loss =  0.3391\n",
            "epoch : 60, loss =  0.3099\n",
            "epoch : 70, loss =  0.2874\n",
            "epoch : 80, loss =  0.2694\n",
            "epoch : 90, loss =  0.2546\n",
            "epoch : 100, loss =  0.2422\n",
            "accuracy =  0.9035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnuOvCxH3zP",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and Data Loader"
      ]
    }
  ]
}